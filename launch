#!/bin/bash

## Define usage function
general_usage(){
	echo -e '\e[32mlaunch <pipeline> <samplesheet.txt> [options]\e[0m'
}

## Get parent path for linking files
parent_path=$( cd "$(dirname "${BASH_SOURCE[0]}")" ; pwd -P )

## Load global modules
module load python/3.6.6
module load r/3.3.1

# Select pipeline
case $1 in 

	googleSync)
		
		## Load pipeline-specific modules
		module load python/3.6.6

		## Create and activate virtual environment with requirements
		python -m virtualenv googleEnv && source googleEnv/bin/activate && pip3 install google-api-python-client oauth2client

		## Build name for today's SequencingData sheet
		today=`date +%Y-%m-%d`
		fileName="/proj/phanstiel_lab/software/RNApipe/config/SequencingData_${today}.tsv"

		# Move existing tsv's into the backup directory
		mv /proj/phanstiel_lab/software/RNApipe/config/*.tsv /proj/phanstiel_lab/software/RNApipe/config/backup/

		## Link googleAPIquickstart.py and JSON files
		cp "${parent_path}/scripts/googleSync/googleAPIquickstart.py" "${PWD}/googleAPIquickstart.py"
		cp "${parent_path}/scripts/googleSync/credentials.json" "${PWD}/credentials.json"
		cp "${parent_path}/scripts/googleSync/token.json" "${PWD}/token.json"

		## Launch googleAPIquickstart.py, which calls the Sheets API to pull the info from Google Drive. Write the results to a new file.
		python ./googleAPIquickstart.py > $fileName

		## Unlink googleAPIquickstart.py 
		rm ./googleAPIquickstart.py
		rm ./credentials.json
		rm ./token.json

		## Remove
		rm -r ./googleEnv 
		
		;;

	rnaseq)
		
		## Load pipeline-specific modules
		module load bbmap
		module load subread

		## Copy appropriate snakemake, config, and cluster files
		cp "${parent_path}/snakefiles/rnaseq.snakefile" "${PWD}/Snakefile"
		cp "${parent_path}/config/config.yaml" "${PWD}/config.yaml"
		cp "${parent_path}/config/cluster.yaml" "${PWD}/cluster.yaml"
		rsync -az --ignore-errors "${2}" "${PWD}/$(basename ${2})" #suppress error if file already exists in directory

		## Replace sample sheet in config file (come up with better/python parser to handle additional options)
		sed -i 's|^\(\s*samples\s*:\s*\).*|\1'"${2}"'|' config.yaml

		## Generate DAG
		snakemake --dag | dot -Tpdf > dag.pdf

		## Launch Cluster Command
		snakemake -j 999 -s Snakefile --configfile config.yaml --latency-wait 500 -d "${PWD}" --cluster-config cluster.yaml --cluster "sbatch -p {cluster.partition} -n {cluster.tasks} -N {cluster.nodes} --mem={cluster.mem} -t {cluster.time} --output {cluster.output}"

		echo 'rnaseq snakemake running in background via nohub -- check nohub.out for progress (tail -f nohup.out)'

		;;

	rnaseq_PE)

		## Copy appropriate snakemake, config, and cluster files
		cp "${parent_path}/snakefiles/rnaseq_PE.snakefile" "${PWD}/Snakefile"
		cp "${parent_path}/config/config_rnaseq_PE.yaml" "${PWD}/config.yaml"
		cp "${parent_path}/config/cluster_rnaseq_PE.yaml" "${PWD}/cluster.yaml"
		rsync -az --ignore-errors "${2}" "${PWD}/$(basename ${2})" #suppress error if file already exists in directory

		## Replace sample sheet in config file (come up with better/python parser to handle additional options)
		sed -i 's|^\(\s*samples\s*:\s*\).*|\1'"${2}"'|' config.yaml

		## Generate DAG
		# snakemake --dag | dot -Tpdf > dag.pdf

		## Launch Cluster Command
		# snakemake -j 999 -s Snakefile --configfile config.yaml --latency-wait 500 -d "${PWD}" --cluster-config cluster.yaml --cluster "sbatch -p {cluster.partition} -n {cluster.tasks} -N {cluster.nodes} --mem={cluster.mem} -t {cluster.time} --output {cluster.output}"
		snakemake -s Snakefile --configfile config.yaml --latency-wait 60

		# echo 'rnaseq snakemake running in background via nohub -- check nohub.out for progress (tail -f nohup.out)'

		;;

	chipseq)
		
		## Load pipeline-specific modules
		# module load fastqc/0.11.5
		# module load trim_galore/0.4.3
		# module load bwa/0.7.17
		# module load samtools/1.8
		# module load java/10.0.2
		# module load bedtools/2.26
		# module load macs/2016-02-15

		## Copy appropriate snakemake, config, and cluster files
		cp "${parent_path}/snakefiles/chipseq.snakefile" "${PWD}/Snakefile"
		cp "${parent_path}/config/config.yaml" "${PWD}/config.yaml"
		cp "${parent_path}/config/cluster.yaml" "${PWD}/cluster.yaml"
		rsync -az --ignore-errors "${2}" "${PWD}/$(basename ${2})" #suppress error if file already exists in directory

		## Replace sample sheet in config file (come up with better/python parser to handle additional options)
		sed -i 's|^\(\s*samples\s*:\s*\).*|\1'"${2}"'|' config.yaml

		# snakemake -s Snakefile --configfile config.yaml --latency-wait 60
		nohup snakemake -j 999 -s Snakefile --configfile config.yaml --latency-wait 500 -d "${PWD}" --cluster-config cluster.yaml --cluster "sbatch -p {cluster.partition} -n {cluster.tasks} -N {cluster.nodes} --mem={cluster.mem} -t {cluster.time} --output {cluster.output}" &

		echo -e '\e[32mrnaseq snakemake running in background via nohub -- check nohub.out for progress (tail -f nohup.out)\e[0m'
		;;

	chipseq_PE)

		## Copy appropriate snakemake, config, and cluster files
		cp "${parent_path}/snakefiles/chipseq_PE.snakefile" "${PWD}/Snakefile"
		cp "${parent_path}/config/config_chipseq_PE.yaml" "${PWD}/config.yaml"
		cp "${parent_path}/config/cluster_chipseq_PE.yaml" "${PWD}/cluster.yaml"
		rsync -az --ignore-errors "${2}" "${PWD}/$(basename ${2})" #suppress error if file already exists in directory

		## Replace sample sheet in config file (come up with better/python parser to handle additional options)
		sed -i 's|^\(\s*samples\s*:\s*\).*|\1'"${2}"'|' config.yaml

		## Generate DAG
		# snakemake --dag | dot -Tpdf > dag.pdf

		## Launch Cluster Command
		nohup snakemake -j 999 -s Snakefile --configfile config.yaml --latency-wait 500 -d "${PWD}" --cluster-config cluster.yaml --cluster "sbatch -p {cluster.partition} -n {cluster.tasks} -N {cluster.nodes} --mem={cluster.mem} -t {cluster.time} --output {cluster.output}" &
		# snakemake -s Snakefile --configfile config.yaml --latency-wait 60

		echo 'chipseq_PE snakemake running in background via nohub -- check nohub.out for progress (tail -f nohup.out)'

		;;

	bcl2fastq)
		
		## Sample sheet error message
		case $2 in

			'-h' | '--help' | ' ' | '')
				echo -e '\e[31mProvide a sample sheet for bcl2fastq\e[0m'
				exit 2
				;;
		esac

		## Copy sample sheet to current directory
		rsync -az --ignore-errors "${2}" "${PWD}/SampleSheet.csv" #suppress error if file already exists in directory

		## Link bcl2fastq wrapper
		ln -s "${parent_path}/scripts/run_bcl2fastq.sh" "${PWD}/run_bcl2fastq.sh"

		## Launch bcl2fastq wrapper
		./run_bcl2fastq.sh

		## Unlink juicer wrapper
		unlink run_bcl2fastq.sh
		
		;;

	juicer)
		
		## Sample sheet error message
		case $2 in

			## Help message
			'-h' | '--help' | ' ' | '')
				echo -e '\e[31mSelect between "prep" (to make juicer directories and split fastqs) and "run" (to launch juicer processing jobs).\e[0m'
				exit 2
				;;

			## If running prep...
			'prep')

				## 	Link juicer_pipeline_prep wrapper
				ln -s "${parent_path}/scripts/juicer_pipeline_prep.py" "${PWD}/juicer_pipeline_prep.py"

				## Launch juicer_pipeline_prep wrapper
				python3 ./juicer_pipeline_prep.py ${@:3}

				## Unlink juicer_pipeline_prep wrapper
				unlink juicer_pipeline_prep.py

				;;

			## If running run...
			'run')

				## Link juicer_pipeline_run wrapper
				ln -s "${parent_path}/scripts/juicer_pipeline_run.py" "${PWD}/juicer_pipeline_run.py"

				## Launch juicer_pipeline_run wrapper
				python3 ./juicer_pipeline_run.py ${@:3}

				## Unlink juicer_pipeline_run wrapper
				unlink juicer_pipeline_run.py

				;;
		esac

		;;

	mega)
		
		## Link mega wrapper
		ln -s "${parent_path}/scripts/mega_pipeline.py" "${PWD}/mega_pipeline.py"

		## Launch mega wrapper
		python3 ./mega_pipeline.py ${@:2}

		## Unlink mega wrapper
		unlink mega_pipeline.py
		
		;;

	merging)
		
		case $2 in

			'-h' | '--help' | ' ' | '')
				echo -e '\e[31mProvide a sample sheet for merging\e[0m'
				exit 2
				;;

		esac

		case $3 in

			'--merge' | '-merge' | '-m' | '--mergeBy' | '-mergeBy')

				## Load R module
				module load r/3.6.0
				
				## Link merge script
				ln -s "${parent_path}/scripts/merge.R" "${PWD}/merge.R"

				## Launch merge script			
				Rscript merge.R $2 ${@: 4}

				## Unlink merge script
				unlink merge.R
				;;

			'-h' | '--help' | ' ' | '')
				
				echo -e '\e[32mUsage: launch merging <samplesheet.txt> --merge Col1 Col2 Col3...\e[0m'
				echo -e '\e[33mAvailable Columns: ' $(head -n 1 $2) '\e[0m'
				exit 2
				;;			

		esac


		;;

	subsample)
		
		## Print help messages for additional options
		case $2 in

			'-h' | '--help' | ' ' | '')
				echo -e '\e[31mProvide a fastq file list to subsample (ls path/to/*.fastq > files.txt)\e[0m'
				exit 2
				;;
		esac

		case $3 in

			'-h' | '--help' | ' ' | '')
				echo -e '\e[31mSpecify how many reads as a number or fraction (eg. 10000 or 0.001)\e[0m'
				exit 2
				;;
		esac

		## Create config file to pass in options
		cat > config.yaml <<-EOF
			samples: '${2}'
			subsample_reads: "${3}"
		EOF

		## Copy appropriate snakemake, and cluster files
		cp "${parent_path}/snakefiles/subsample.snakefile" "${PWD}/Snakefile"
		cp "${parent_path}/config/cluster_subsample.yaml" "${PWD}/cluster.yaml"

		# snakemake -s Snakefile --configfile config.yaml --latency-wait 60
		nohup snakemake -j 999 -s Snakefile --configfile config.yaml --latency-wait 500 -d "${PWD}" --cluster-config cluster.yaml --cluster "sbatch -p {cluster.partition} -n {cluster.tasks} -N {cluster.nodes} --mem={cluster.mem} -t {cluster.time} --output {cluster.output}" &

		echo -e '\e[32mrnaseq snakemake running in background via nohub -- check nohub.out for progress (tail -f nohup.out)\e[0m'

		;;

	'-h' | '--help' | ' ' | '')
		general_usage
		;;

esac